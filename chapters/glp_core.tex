% chapters/glp_core.tex - GLP Core

\chapter{GLP Core}
\label{ch:glp-core}

\section{GLP}\label{section:GLP}

We present GLP as an extension of Logic Programs: The syntax is extended with reader variables $X?$, where $X$ and $X?$ form a reader/writer pair, and with the Single-Reader/Single-Writer syntactic restriction on clauses.  For example, here is the quintessential concurrent logic program for merging two streams (incrementally constructed, potentially unbounded lists), written in GLP.  Its first two arguments are the input streams to be merged,  the third is the merged output stream:

\Program{GLP Fair Stream Merger}\label{program:merge}
\begin{small}
\begin{verbatim}
merge([X|Xs],Ys,[X?|Zs?]) :- merge(Ys?,Xs?,Zs). % output from first stream
merge(Xs,[Y|Ys],[Y?|Zs?]) :- merge(Xs?,Ys?,Zs). % output from second stream
merge([],[],[]).                                % terminate on empty streams
\end{verbatim}
\end{small}
Note that in each clause, each reader or writer occurs at most once.

The operational semantics of GLP extends that of LP as follows:
\begin{enumerate}
\item \textbf{Synchronisation}: Unification may only instantiate writers, so in addition to succeed/fail, unification may suspend if it requires instantiating readers.

\item \textbf{Communication}: When a unifying writer assignment binds a writer $X$ to a term $T$, the message  $X? := T$ encoding its induced reader assignment is created and added to the configuration. Its application happens asynchronously, realizing a message $T$ from the single occurrence of $X$ to the single occurrence of $X?$.

\item \textbf{Deterministic clause selection}: The first applicable clause is chosen, not nondeterministically as in LP. This provides for the fairness of \verb|merge| presented above:  As long as the two input streams are available the output dovetails the two inputs, due to switching their order in the recursive call of the first clause; as long as only one stream is available, its elements are copied to the output; and when both streams are unavailable the goal suspends.
\end{enumerate}

The remainder of this section presents GLP syntax, nondeterministic operational semantics, and safety properties. A deterministic `workstation implementation-ready' transition-system specification for GLP is presented in Appendix~\ref{appendix:irGLP}.

\subsection{GLP Syntax}

\mypara{Reader/Writer pairs}
GLP extends Logic Programs with paired reader/writer variables, where a \emph{writer} $X$ is a single-assignment variable (promise) and its \emph{paired reader $X?$} provides read-only access to the (future) value of $X$. We denote by $V$ the set of all writers, $V?$ the set of all readers and, $\mathcal{V} = V \cup V?$ the set of all variables, where for each writer $X \in V$ there exists a paired reader $X? \in V?$.
We view $?$ as an identity suffix operator on non-writers, namely  $(X?)?=X?$ for $X?\in V?$ and $T?=T$ for $T\notin \calV$.
We use $\calG_?$ to denote the set of all goals over $\calV$ (i.e., goals that may contain both readers and writers), and for a GLP program $M$, $\calG_?(M)$ denotes the subset of $\calG_?$ restricted to the vocabulary of $M$.


\mypara{Single-Reader/Single Writer (SRSW)} The fundamental requirement in GLP is \emph{single-writer}: any writer may occur at most once in any state of a computation, ensuring there can be no conflict when writing on a logic variable. We extend it to the \emph{single-reader/single-writer (SRSW) requirement} that any reader also occurs at most once. The reason is that with multiple instances of a reader, instantiating the writer to a term containing another writer would give all instances of the paired reader access to that writer, violating the single-writer requirement.
The SRSW requirement is realized by two complementary concepts:
\begin{enumerate}
    \item \emph{SRSW syntactic restriction on clauses}: Variables in a clause occur as reader/writer pairs, with exactly one of each.
    \item \emph{SRSW invariant}:  Given a resolvent that satisfies the SRSW requirement, applying to it a goal reduction with a clause that satisfies the SRSW syntactic restriction produces a new resolvent that also satisfies the SRSW requirement.
\end{enumerate}
This SRSW syntactic restriction excludes programs like the equality definition $X=X$ as it has two occurrences of the writer $X$. At the same time it
eliminates the need for distributed atomic unification~\cite{kleinman1990distributed}—replacing it with efficient point-to-point communication of a single assignment from the single occurrence of a writer to the single occurrence of its paired reader.

\mypara{No writer-to-writer binding (WxW)}
In addition, GLP requires \emph{no writer-to-writer} binding (WxW).  A reader/writer pair $X?/X$ is a communication channel from the writer $X$ to the reader $X?$.
It two writers $X$ and $Y$ are unified during execution, the SRSW requirement implies that no occurrences of either $X$ or $Y$ are left to instantiate them, and therefore their paired readers $X?$ and $Y?$ will be left \emph{abandoned}.  Combined,  the WxW and SRSW restrictions ensure that communication channels are properly closed, with no reader is left abandoned by their paired variable.\footnote{We discuss below a relaxation, allowing a reader to abandon its paired writer using anonymous variables \texttt{\_}, which is useful in case there is no need to read the channel any more.}

\subsection{GLP Operational semantics}

\subsection{Writer and Reader Assignments}

When a goal unifies with a clause head, values flow in one direction: writers can
receive values, readers cannot. A \emph{writer assignment} captures exactly which
writers get bound and to what. The \emph{induced reader assignment} then propagates
those values to the paired readers. This asymmetry---writers are assigned, readers
receive---is fundamental to GLP's communication model.

\begin{definition}[Writer Assignment, Reader Assignment, Suspension Set]
\label{definition:GLP-unification}

A \temph{writer assignment} is a substitution $\sigma$ whose domain is writers
($V_\sigma \subset V$) that:
\begin{enumerate}
    \item does not bind writers to writers: if $X \ne X\sigma$ for $X \in V$
          then $X\sigma \notin V$
    \item does not form cycles through readers: $X?$ does not occur in $X\sigma$
          for any $X \in V_\sigma$
\end{enumerate}

A \temph{reader assignment} is a substitution $\sigma$ whose domain is readers
($V_\sigma \subset V?$).

If $\sigma$ is a writer assignment then its \temph{induced reader assignment} is
the reader assignment $\sigma?$ defined by $X?\sigma? = X\sigma$ for every
$X \in V_\sigma$.

The \temph{suspension set} of a (regular) substitution $\sigma$ is
$W_\sigma := \{X? \in V? : X?\sigma \notin \calV\}$.

\temph{Writer unification} of two terms:
\begin{enumerate}
    \item \temph{succeeds with $\sigma$} if they have an mgu $\sigma$ that is a
          writer assignment.
    \item else \temph{suspends on $W_\sigma$} if they have a (regular) mgu $\sigma$
    \item else \temph{fails}
\end{enumerate}
\end{definition}

\begin{remark}[How Values Flow]
The induced reader assignment is the mechanism by which readers receive values.
When writer $X$ is assigned value $T$, its paired reader $X?$ automatically
receives that same value $T$. This is point-to-point communication: one writer
to one reader, with no possibility of conflict.

The suspension set identifies which readers are ``blocking''---they appear where
a non-variable value is needed, but their paired writers have not been assigned yet.
Unification suspends until those writers receive values, at which point the induced
reader assignments make the values available and unification can proceed.
\end{remark}

\begin{remark}[Why Writer-to-Writer Assignment is Forbidden]
Condition 1 prohibits assigning a writer to another writer. If writers $X$ and $Y$
were unified, the SRSW requirement implies no occurrences of either remain to
assign them values. Their paired readers $X?$ and $Y?$ would be
\emph{abandoned}---waiting forever for values that will never arrive. The
implementation treats writer-to-writer unification as failure, not suspension.
\end{remark}

\subsubsection{Writer Unification Cases}

The complete enumeration of all writer unification cases between goal and head arguments appears in Appendix~\ref{appendix:unification-catalog}.

For compound terms, writer unification proceeds in two phases:

\begin{enumerate}
\item \textbf{Collection phase:} Process arguments left-to-right, accumulating tentative writer bindings $\hat{\sigma}_w$ and a preliminary suspension set $S$ (readers matched against non-variable terms whose paired writers are not yet in $\hat{\sigma}_w$). If a structural mismatch occurs (e.g., distinct constants, incompatible functors), fail immediately.

\item \textbf{Resolution phase:} Apply $\hat{\sigma}_w$ to the preliminary suspension set: $S' = \{X? \in S : X \notin \text{dom}(\hat{\sigma}_w)\}$. If $S' = \emptyset$, succeed with $\hat{\sigma}_w$. If $S' \neq \emptyset$, suspend on $S'$.
\end{enumerate}

The resolution phase is essential: a reader $X?$ encountered before its paired writer $X$ is bound should not cause suspension if a later argument position binds $X$. The suspension decision is deferred until all argument positions have been processed.

\begin{remark}[Key Observations]
Goal writers always succeed (can be assigned any value). Goal readers suspend against non-variables (must wait for their paired writer). Head readers behave like head writers during unification since the fresh variable can be assigned; the distinction matters only in the clause body.
\end{remark}

\subsubsection{Worked Examples}

\mypara{Example 1: Success}
Goal $g = p(X, a)$, Head $h = p(b, Y)$ (after renaming).

Unification: $X$ matches $b$, $a$ matches $Y$. Both are writer-to-constant.
Writer assignment: $\{X \mapsto b, Y \mapsto a\}$. Succeeds.

\mypara{Example 2: Suspension}
Goal $g = p(X?, a)$, Head $h = p(b, Y)$.

First argument: $X?$ (goal reader) against $b$ (constant). A regular mgu would
require $X? \mapsto b$, but readers cannot be assigned. Suspension set: $\{X?\}$.
Suspends on $\{X?\}$, waiting for the paired writer $X$ to be assigned.

\mypara{Example 2b: Resolution of Preliminary Suspension}
Goal $g = p(X?, X)$, Head $h = p(a, a)$ (constant $a$ in both positions).

Collection phase: First argument $X?$ against $a$---reader against constant, add $X?$ to preliminary suspension set $S = \{X?\}$. Second argument $X$ against $a$---writer against constant, add $X \mapsto a$ to $\hat{\sigma}_w$.

Resolution phase: Apply $\hat{\sigma}_w = \{X \mapsto a\}$ to $S = \{X?\}$. Since $X \in \text{dom}(\hat{\sigma}_w)$, remove $X?$ from set. Result: $S' = \emptyset$.

Succeeds with $\{X \mapsto a\}$. The induced reader assignment gives $X? = a$.

This example demonstrates why the two-phase approach is necessary. A naive left-to-right algorithm that suspends on the first reader would incorrectly suspend, missing the binding information from the second argument.

\mypara{Example 3: Failure}
Goal $g = p(a, b)$, Head $h = p(a, c)$.

First argument: $a = a$, succeeds. Second argument: $b \ne c$, no mgu exists. Fails.

\mypara{Example 4: Writer-to-Writer Failure}
Goal $g = p(X)$, Head $h = p(Y)$.

A regular mgu exists: $\{X \mapsto Y\}$. But this assigns writer to writer,
violating condition 1. No writer assignment exists. Fails (not suspends).

\begin{remark}[Programming Style: Fold Unifications into the Head]
When a clause needs to test the structure of an argument, fold the pattern directly into the clause head rather than using explicit unification in the guard.

For example, to process a list with at least two elements:
\begin{verbatim}
% Avoid: explicit unification in guard
merge_tree(Streams, Out?) :-
    Streams = [_,_|_] |
    merge_layer(Streams?, Layer),
    merge_tree(Layer?, Out).

% Prefer: pattern in head
merge_tree([X,Y|Rest], Out?) :-
    merge_layer([X?,Y?|Rest?], Layer),
    merge_tree(Layer?, Out).
\end{verbatim}

The second form is correct GLP style. The first form has \verb|Streams| appearing both in the head (as writer) and in the guard (as another occurrence), which can confuse SRSW analysis. By folding the structural test into the head pattern, the clause clearly shows that \verb|X|, \verb|Y|, and \verb|Rest| are bound by pattern matching and then read in the body.

This principle applies generally: if you find yourself writing \verb|X = Pattern| in a guard where \verb|X| comes from the head, restructure the clause to put the pattern directly in the head.
\end{remark}

Renaming  (Definition~\ref{definition:renaming}) is extended to respect variable pairing:
\begin{definition}[GLP Renaming]\label{definition:GLP-renaming}
 Two GLP terms $T, T'$ have a variable in common if for some writer $X\in V$, either $X$ or $X?$ occur in $T$ and either $X$ or $X?$ occur in $T'$. A \temph{GLP renaming} is a renaming substitution $\sigma: \mathcal{V} \mapsto \mathcal{V}$ such that for each $X\in V$: $X\sigma \in V$ and $X?\sigma = (X\sigma)?$.
\end{definition}

\begin{definition}[GLP Goal/Clause Reduction]\label{definition:GLP-goal-clause-reduction}
 Given GLP goal $A$ and clause $C$,  with $H \verb|:-| B$ being the result of the GLP renaming of $C$ apart from $A$,
 the \temph{GLP reduction} of $A$ with $C$ \temph{succeeds with result} $(B,\sigma)$,
\temph{suspends on $W$}, or \temph{fails}, respectively, depending on the result of the writer unification of $A$ and $H$.
\end{definition}

The GLP operational semantics is defined via the following transition system, which employs the notions defined above to extend LP (Definition~\ref{definition:lp-ts}). It abstracts-away goal suspension and failure; these are used in the implementation-ready specifications (Appendixes~\ref{appendix:irGLP} and~\ref{appendix:irmaGLP}) for explicit goal scheduling, suspension and activation.
\begin{definition}[GLP Transition System]\label{definition:GLP-ts}
Given a GLP program $M$, an \temph{asynchronous resolvent} over $M$ is a pair $(G,\sigma)$ where $G\in \calG_?(M)$ and $\sigma$ is a reader assignment.
%
A transition system $GLP = (\calC,c0,\calT)$ is a \temph{GLP transition system} over $M$ and initial goal $G_0 \in \mathcal{G}_?(M)$ satisfying SRSW if:
\begin{enumerate}
    \item $\calC$ is the set of all asynchronous resolvents over $M$
    \item $c0= (G_0,\emptyset)$
    \item $\calT$ is the set of all transitions $(G,\sigma)\rightarrow (G',\sigma')$ satisfying:
    \begin{enumerate}
        \item \textbf{Reduce:} there exists a unit goal $A \in G$ such that $C \in M$ is the first clause for which the GLP reduction of $A$ with $C$ succeeds with result $(B,\hat\sigma)$,  $G' = (G \setminus \{A\} \cup B)\hat\sigma$, and $\sigma' = \sigma \circ \hat\sigma?$
        \item \textbf{Communicate:} $\hat\sigma = \{X?:=T\} \in \sigma$, $G'= G\hat\sigma$, and $\sigma' = \sigma \setminus \hat\sigma$
\end{enumerate}
\end{enumerate}
\end{definition}
The monotonicity of GLP goal/clause reduction (Proposition~\ref{proposition:GLP-monotonicity}) allows a simple \emph{GLP fairness requirement}: A goal that can be reduced is eventually reduced.


\mypara{Guards and system predicates}
GLP also includes \emph{guards}—predicates that test runtime conditions (e.g., \verb|ground(X)| tests if \verb|X| contains no variables) without modifying state, appearing after clause heads separated by \verb=|=—and \emph{system predicates} that provide access to the GLP runtime state and operating system and hardware capabilities (variable state and name, arithmetic evaluation, timestamps). Guards enable conditional clause selection. The \verb|ground(X)| guard allows relaxing the single-reader constraint for \verb|X?| for the clause it occurs in, as having multiple occurrences of \verb|X?| instantiated to a ground term does not violate the fundamental single-writer requirement.
Their specification appears in Appendix~\ref{appendix:guards-system}.


\subsection{GLP Safety}

Here we prove that, like LP, GLP computations are deductions, but, unlike LP, a goal that can be reduced in a configuration can still be reduced in any subsequent configuration of the computation.

\mypara{GLP computations are deductions}  First we show that the extensions of GLP over LP do not take it outside of the logic programming realm.

\begin{definition}[Pure Logic Variant]\label{definition:pure-logic}
Given a GLP term or goal $T$, the \temph{pure logic variant} $L(T)$ of $T$ is defined by replacing every reader $X?$ in $T$ with its paired writer $X$. Given a GLP computation  $r$, its pure logic variant $L(r)$ is the result of replacing every configuration $(G,\sigma)$ in $r$ by $L(G)$,  removing duplications and labelling the remaining transitions by the mgu of their respective reduction.
\end{definition}
Note that duplications as above result from Communicate transitions.

\begin{restatable}[GLP Computations are Deductions]{proposition}{GLPComputationsareDeductions}\label{theorem:GLP-computation-deduction}
For any finite GLP run $r$, let
$L(r) = G0\xrightarrow{\sigma_1}G_1\xrightarrow{\sigma_2}\ldots G_n$,
with $\sigma = \sigma_1\cdot \ldots \cdot \sigma_n$, then  $(G_ :- G_n)\sigma$ is a logical consequence of $L(M)$.
\end{restatable}

Next, we establish essential safety properties for GLP that distinguish it from standard LP. The key is monotonicity—once a goal becomes reducible in GLP, it remains reducible.

\mypara{SRSW}
\begin{restatable}[SRSW Invariant]{proposition}{SRSWInvariant}\label{proposition:srsw-preservation}
If the initial goal $G_0$ in a $GLP$ run satisfies SRSW, then every goal in the run satisfies SRSW.
\end{restatable}

\mypara{Acyclicity}
The occurs check in readers prevents the formation of circular terms.

\begin{restatable}[Acyclicity]{proposition}{Acyclicity}\label{proposition:acyclicity}
If the initial goal $G_0$ in a $GLP$ run contains no circular terms, then no goal in the run contains a circular term.
\end{restatable}

\mypara{Monotonicity}
Unlike LP where variable instantiation can cause a previously reducible goal to fail, GLP exhibits monotonicity. In a run, if a goal $A$ can be reduced at some point, it remains reducible at all future points in that run, where
``future" implies that readers in $A$  (and only readers) have been further instantiated by other goal reductions.

\begin{restatable}[Reader-Instance]{lemma}{ReaderOnlyInstantiation}\label{lemma:reader-only}
In any $GLP$ run $G_0 \rightarrow G_1 \rightarrow \cdots$, if $G_i \rightarrow G_{i+1}$ via reduction with substitution $\sigma?$ does not reduce $A \in G_{i}$, then $A\tau \in G_{i+1}$ where $\tau$ instantiates only readers.
\end{restatable}

\begin{restatable}[Monotonicity]{proposition}{Monotonicity}\label{proposition:GLP-monotonicity}
In any $GLP$ run $G_0 \rightarrow G_1 \rightarrow \cdots$, if unit goal $A \in G_i$ can reduce with clause $C$, then for any $j > i$, either $A$ has been reduced by step $j$, or there exists $A' \in G_j$ where $A' = A\tau$ for some reader assignment $\tau$, and $A'$ can reduce with $C$.
\end{restatable}

\subsection{Deterministic Transition System for Concurrent GLP}\label{subsection:irGLP}

This section specifies a workstation (single-agent) implementation-ready transition system for GLP with deterministic execution.

The nondeterministic GLP transition system (Definition~\ref{definition:GLP-ts}) specifies \emph{what} computations are valid without prescribing \emph{how} to execute them. The implementation-ready transition system makes three deterministic choices:
\begin{enumerate}
    \item \textbf{Goal order}: Goals are processed front-to-back from an ordered queue. The first goal is selected for reduction.
    \item \textbf{Clause order}: Clauses are tried top-to-bottom. The ``first applicable clause'' is the textually first clause in $M$ for which reduction succeeds.
    \item \textbf{Unification order}: Compound term arguments are unified left-to-right, depth-first. Unification stops at the first suspension or failure encountered.
\end{enumerate}

The left-to-right unification order processes arguments sequentially, but the suspension decision is deferred until all arguments have been examined. This ensures that a reader encountered early can be resolved by a writer binding discovered later. Structural failures (functor mismatch, arity mismatch, distinct constants) are detected immediately.

\begin{definition}[Depth-First Writer Unification]\label{definition:df-unification}
The \temph{depth-first writer unification} of terms $T_1$ and $T_2$, denoted $\mathit{dfunify}(T_1, T_2)$, proceeds in two phases:

\textbf{Phase 1 (Collection):} Traverse the terms, accumulating a tentative writer assignment $\hat\sigma$ and a preliminary suspension set $S$:
\begin{enumerate}
    \item If $T_1$ and $T_2$ are identical: return $(\hat\sigma, S)$ unchanged.
    \item If $T_1$ is a writer:
    \begin{itemize}
        \item If $T_2$ is a writer: \emph{fails} immediately.
        \item Otherwise: add $T_1 := T_2$ to $\hat\sigma$.
    \end{itemize}
    \item If $T_2$ is a writer: add $T_2 := T_1$ to $\hat\sigma$.
    \item If $T_1$ is a reader: add $T_1$ to $S$.
    \item If $T_2$ is a reader: add $T_2$ to $S$.
    \item If $T_1 = f(S_1, \ldots, S_n)$ and $T_2 = g(R_1, \ldots, R_m)$:
    \begin{itemize}
        \item If $f \neq g$ or $n \neq m$: \emph{fails} immediately.
        \item Otherwise, for $i = 1, \ldots, n$ in order, recursively process $(S_i\hat\sigma, R_i\hat\sigma)$, updating $\hat\sigma$ and $S$. If any recursive call fails, \emph{fail}.
    \end{itemize}
\end{enumerate}

\textbf{Phase 2 (Resolution):} Compute the resolved suspension set:
\[
S' = \{X? \in S : X \notin \mathrm{dom}(\hat\sigma)\}
\]
\begin{itemize}
    \item If $S' = \emptyset$: \emph{succeeds} with $\hat\sigma$.
    \item If $S' \neq \emptyset$: \emph{suspends} on $S'$.
\end{itemize}
\end{definition}

\mypara{Example: Resolution of Preliminary Suspension}
Consider goal $p(X?, X)$ against head $p(a, a)$.

Phase 1: First argument $X?$ against $a$—reader against constant, add $X?$ to $S$. Second argument $X$ against $a$—writer against constant, add $X := a$ to $\hat\sigma$. Result: $\hat\sigma = \{X := a\}$, $S = \{X?\}$.

Phase 2: Compute $S' = \{X? \in S : X \notin \mathrm{dom}(\hat\sigma)\}$. Since $X \in \mathrm{dom}(\hat\sigma)$, we have $S' = \emptyset$.

Result: \emph{succeeds} with $\{X := a\}$. The induced reader assignment gives $X? = a$.

Without the two-phase approach, the algorithm would incorrectly suspend at the first argument, missing the binding from the second argument.

\begin{definition}[irGLP Configuration]
An \emph{irGLP configuration} over program $M$ is a triple $R = (Q, S, F)$ where:
\begin{itemize}
\item $Q \in \mathcal{A}^*$ is a sequence of active goals
\item $S \subseteq \mathcal{A} \times 2^{V?}$ contains suspended goals with their suspension sets
\item $F \subseteq \mathcal{A}$ contains failed goals
\end{itemize}
\end{definition}

The irGLP reduction extends GLP reduction by activating goals that were suspended on variables instantiated by the reduction, and explicitly failing goals that do not succeed or suspend.

\begin{definition}[irGLP Goal/Clause Reduction]
Given configuration $(Q, S, F)$ with $Q = A\cdot Q'$, clause $C \in M$ with head $H$ and body $B$ (renamed apart from $A$), the \emph{irGLP reduction} of $A$ with $C$:
\begin{itemize}
\item \textbf{succeeds with} $(B, \hat\sigma, R)$ if $\mathit{dfunify}(A, H)$ succeeds with $\hat\sigma$, and $R = \{G : (G, W) \in S \wedge X?\in W \wedge X?\hat\sigma? \neq X?\}$
\item \textbf{suspends with} $W$ if $\mathit{dfunify}(A, H)$ suspends on $W$
\item \textbf{fails} if $\mathit{dfunify}(A, H)$ fails
\end{itemize}
\end{definition}

\begin{definition}[Implementation-Ready GLP Transition System]
The transition system $\text{irGLP} = (\mathcal{C}, c_0, \mathcal{T})$ over $M$ and initial goal $G_0$ has configurations $\mathcal{C}$ being all irGLP configurations over $M$, with initial configuration $c_0 = (G_0, \emptyset, \emptyset)$, and transitions $\mathcal{T}$ being all transitions $(Q, S, F) \rightarrow (Q', S', F')$ where $Q = A \cdot Q_r$ and:
    \begin{enumerate}
    \item \textbf{Reduce:} If irGLP reduction of $A$ with first applicable clause $C \in M$ succeeds with $(B, \hat\sigma, R)$:
        \begin{itemize}
        \item \textbf{Activate:}  $S' = S \setminus \{(G, W) : G \in R\}$,  $F' = F$
        \item \textbf{Schedule:} $Q' = (Q_r \cdot B \cdot R)\hat\sigma\hat\sigma?$
        \end{itemize}
    \item \textbf{Suspend:} Else if $W = \bigcup_{C \in M} W_{C} \neq \emptyset$ then $Q' = Q_r$, $S' = S \cup \{(A, W)\}$, $F' = F$
    \item \textbf{Fail:} Else, $Q' = Q_r$, $S' = S$, $F' = F \cup \{A\}$.
    \end{enumerate}
\end{definition}

\begin{remark}[Immediate vs.\ Asynchronous Communication]
The GLP transition system (Definition~\ref{definition:GLP-ts}) models communication asynchronously in two steps:
\begin{enumerate}
\item \textbf{Reduce}: The writer assignment $\hat\sigma$ is applied to the goal. Its induced reader assignment $\hat\sigma?$ is added to the pending substitution $\sigma$.
\item \textbf{Communicate}: Later, an assignment $\{X? := T\}$ is selected from $\sigma$ and applied to the goal.
\end{enumerate}

The irGLP transition system combines these into a single step. The Schedule operation applies both the writer assignment and its induced reader assignment immediately:
\[
Q' = (Q_r \cdot B \cdot R)\hat\sigma\hat\sigma?
\]

This simplification is valid for single-agent execution because all variables are local---there is no network delay between writer and reader. The observable behavior is identical: the reader receives its value before any subsequent goal can observe it.

In multiagent GLP, where readers and writers may reside on different machines, the two-step model becomes essential. The pending substitution $\sigma$ represents messages in flight between agents.
\end{remark}

\begin{remark}[Scheduling Freedom]
The monotonicity property (Proposition~\ref{proposition:GLP-monotonicity}) ensures that a goal reducible in configuration $c$ remains reducible in any subsequent configuration. This provides significant scheduling freedom:
\begin{itemize}
\item \textbf{Any fair schedule works}: As long as every reducible goal eventually gets a turn, the computation makes progress.
\item \textbf{No complex failure handling}: Unlike systems where delays can cause failures, a message arriving late in GLP does not invalidate pending computations.
\item \textbf{Distributed execution}: In a distributed setting, network delays affect performance but not correctness.
\end{itemize}
The GLP fairness requirement is simply: a goal that can be reduced is eventually reduced.
\end{remark}

\section{Guards}
\label{sec:guards}

Guards are predicates that test conditions without side effects. A clause is applicable only if its guard succeeds. Guards appear between the clause head and the body, separated by \verb$|$:

\begin{verbatim}
Head :- Guard | Body.
\end{verbatim}

If the guard suspends (e.g., tests an unbound variable), the clause is not yet applicable. If the guard fails, the next clause is tried. If the guard succeeds, the clause commits and executes its body.

\subsection{Built-in Guards}
\label{sec:builtin-guards}

\mypara{Type Guards}
Type guards test the structure of a value:
\begin{itemize}
\item \verb|ground(X)| --- succeeds if \verb|X| contains no unbound variables
\item \verb|known(X)| --- succeeds if \verb|X| is bound (may contain unbound subterms)
\item \verb|unknown(X)| --- succeeds if \verb|X| is an unbound variable
\item \verb|integer(X)|, \verb|number(X)|, \verb|constant(X)| --- test for specific types
\item \verb|compound(X)|, \verb|tuple(X)| --- test for compound terms
\item \verb|is_list(X)| --- tests for proper list structure
\end{itemize}

The \verb|ground(X)| guard is special: it relaxes the single-reader constraint for \verb|X?| within the clause, permitting multiple reader occurrences since a ground term contains no writers.

\mypara{Arithmetic Guards}
Arithmetic guards compare numeric values:
\begin{itemize}
\item \verb|X =:= Y| --- numeric equality
\item \verb|X < Y|, \verb|X > Y|, \verb|X =< Y|, \verb|X >= Y| --- comparisons
\end{itemize}

These suspend if either operand is unbound.

\mypara{Equality Guard}
The guard \verb|X =?= Y| tests ground equality: succeeds if both are ground and equal, fails if both are ground and different, suspends if either contains unbound readers.

\mypara{Control Guards}
The \verb|otherwise| guard succeeds when all previous clauses for the predicate failed (not suspended). This enables default case handling.

\subsection{Guard Negation}
\label{sec:guard-negation}

Any negatable guard \verb|G| can be negated using \verb|~G|. The negated guard succeeds when \verb|G| fails, fails when \verb|G| succeeds, and suspends when \verb|G| suspends.

\begin{verbatim}
lookup(Key, [(K,V)|_], V?) :- Key? =?= K? | true.
lookup(Key, [(K,_)|Rest], V?) :- ~(Key? =?= K?) | lookup(Key?, Rest?, V).
\end{verbatim}

Type guards and \verb|=?=| are negatable. Arithmetic comparisons and \verb|otherwise| are not.

\subsection{Defined Guards}
\label{sec:defined-guards}

A \emph{defined guard} is a user-defined predicate that can be called in guard position. It must be a \emph{unit clause}---a clause with no guards and no body (or body \verb|true|).

\mypara{Type Tests}
A unit clause can define a type test:

\begin{verbatim}
channel(ch(_, _)).
\end{verbatim}

When called in guard position, the pattern is matched against the argument:

\begin{verbatim}
process(X, ok) :- channel(X?) | handle(X?).
process(_, error) :- otherwise | true.
\end{verbatim}

The compiler transforms this by \emph{partial evaluation}---unfolding the unit clause at compile time:

\begin{verbatim}
process(ch(_, _), ok) :- handle(ch(_, _)?).
process(_, error) :- otherwise | true.
\end{verbatim}

\mypara{Channel Operations}
Channel operations are defined as unit clauses:

\begin{verbatim}
send(X, ch(In, [X?|Out?]), ch(In?, Out)).
receive(X?, ch([X|In], Out?), ch(In?, Out)).
new_channel(ch(Xs?, Ys), ch(Ys?, Xs)).
\end{verbatim}

These enable abstract channel manipulation in guards. Consider a relay that forwards messages from a stream to a channel:

\begin{verbatim}
relay([X|In], Out?, Ch) :- send(X?, Ch?, Ch1) | relay(In?, Out, Ch1?).
relay(In?, [X?|Out?], Ch) :- receive(X, Ch?, Ch1) | relay(In, Out, Ch1?).
relay([], [], ch([], [])).
\end{verbatim}

The first clause sends stream element \verb|X| to the channel. The second receives from the channel to the output stream. The compiler unfolds the defined guards:

\begin{verbatim}
relay([X|In], Out?, ch(ChIn, [X?|ChOut?])) :- relay(In?, Out, ch(ChIn?, ChOut)).
relay(In?, [X?|Out?], ch([X|ChIn], ChOut?)) :- relay(In, Out, ch(ChIn?, ChOut)).
relay([], [], ch([], [])).
\end{verbatim}

The abstract form is clearer; the expanded form shows what actually executes.

\mypara{Channel Allocation}
The \verb|new_channel| guard allocates a cross-linked channel pair:

\begin{verbatim}
make_pair(C1?, C2?) :- new_channel(C1, C2) | true.
\end{verbatim}

Variables \verb|C1| and \verb|C2| are writers in the guard (allocated there) and readers in the head (returned to caller). After partial evaluation:

\begin{verbatim}
make_pair(ch(X1?, X2), ch(X2?, X1)).
\end{verbatim}

The channels are cross-linked: what is written to one is read from the other.

\mypara{Response Binding}
The cold-call protocol uses \verb|new_channel| to create a response:

\begin{verbatim}
bind_response(yes, accept(RemoteCh?), LocalCh?) :-
    new_channel(LocalCh, RemoteCh) | true.
bind_response(no, reject, none).
\end{verbatim}

When accepting, cross-linked channels are allocated. \verb|RemoteCh| is sent to the caller; \verb|LocalCh| is kept locally. After partial evaluation:

\begin{verbatim}
bind_response(yes, accept(ch(X2?, X1)), ch(X1?, X2)).
bind_response(no, reject, none).
\end{verbatim}

\subsection{SRSW Rules for Defined Guards}
\label{sec:srsw-defined-guards}

When a guard allocates variables (like \verb|new_channel|), those variables are writers in the guard and may be readers elsewhere:

\begin{center}
\begin{tabular}{lll}
\textbf{Position} & \textbf{Form} & \textbf{Meaning} \\
\hline
Head & \verb|X| (writer) & Receives value from caller \\
Head & \verb|X?| (reader) & Returns value to caller \\
Guard & \verb|X| (writer) & Guard provides this value \\
Guard & \verb|X?| (reader) & Reads from head or earlier guard \\
Body & \verb|X| (writer) & Body provides this value \\
Body & \verb|X?| (reader) & Reads from head or guard \\
\end{tabular}
\end{center}

For allocation guards like \verb|new_channel(C1, C2)|:
\begin{itemize}
\item \verb|C1| and \verb|C2| are writers in the guard (allocated there)
\item They appear as readers in the head (\verb|C1?|, \verb|C2?|) to return to caller
\end{itemize}

The complete reference for guards appears in Appendix~\ref{app:glp-reference}.

\section{Exercises}

\begin{enumerate}
\item Trace the full computation of \verb|merge([1], [a], Out)| showing all configurations.

\item What happens if we query \verb|merge(X, Y, [1,2,3])| with $X$ and $Y$ uninstantiated? Explain why.

\item Explain why monotonicity fails in standard LP. Give a concrete example where a reducible goal becomes unreducible.

\item Design a goal that never terminates but is fair (every subgoal gets reduced infinitely often).

\item Prove that if all goals in a GLP computation eventually become reducible, the computation is deadlock-free.
\end{enumerate}

% chapters/streams.tex - Streams, Buffered Communication, Objects and Monitors

\chapter{Streams}
\label{ch:streams}

This chapter presents stream-based concurrent programming in \GLP: producer-consumer patterns, buffered communication for flow control, and stateful servers (objects and monitors).

%% ============================================
%% Section 1: Stream Fundamentals
%% ============================================

\section{Introduction}
\label{sec:streams-intro}

A \emph{stream} is an incrementally-constructed, potentially-indefinite list. Unlike a complete list that exists all at once, a stream is built element by element during computation. The producer may continue indefinitely, or may eventually close the stream by binding its tail to the empty list \verb|[]|.

This distinction has important consequences for consumer design:
\begin{itemize}
\item If a stream is \emph{bounded} (will eventually close), the consumer should have a clause for \verb|[]| to handle termination.
\item If a stream is \emph{indefinite} (never intended to close), the consumer should \emph{not} have a clause for \verb|[]|. Instead, it should fail if the stream unexpectedly terminates, signaling an error condition.
\end{itemize}

This design principle ensures that protocol violations are detected rather than silently ignored.

\section{Producers and Consumers}
\label{sec:streams-producer-consumer}

The simplest stream pattern pairs a producer that generates elements with a consumer that processes them. Consider a producer that counts down from $N$:

\begin{verbatim}
producer([], 0).
producer([N?|Xs?], N) :- N? > 0 | N1 := N? - 1, producer(Xs, N1?).
\end{verbatim}

The producer has two clauses:
\begin{itemize}
\item When $N = 0$, close the stream with \verb|[]|
\item Otherwise, emit $N$ as the head, decrement, and continue with the tail
\end{itemize}

This clause illustrates list structure unification (Appendix~\ref{appendix:list-unification}). When the goal \verb|producer(H, 5)| matches the head \verb|producer([N?|Xs?], N)|, the goal writer \verb|H| unifies with the compound term \verb|[N?|Xs?]|. This succeeds with $\{H \leftarrow [N?|Xs?]\}$---the goal writer receives the entire list structure. The head variables \verb|N| and \verb|Xs| are fresh writers; their paired readers \verb|N?| and \verb|Xs?| appear in the structure assigned to \verb|H|, establishing the communication channel through which values will flow.

A consumer that sums stream elements:

\begin{verbatim}
consumer([], Sum, Sum?).
consumer([X|Xs], Sum, Result?) :- ground(X?) |
    Sum1 := Sum? + X?,
    consumer(Xs?, Sum1?, Result).
\end{verbatim}

\begin{formal}{SRSW in Continuation Calls}
\label{formal:srsw-continuations}

The recursive call in the consumer passes readers \verb|Xs?|, \verb|Sum1?|, and
\verb|Result|---not writers. This is required by SRSW and correct by semantics.

\mypara{Why Readers in Continuations?}
When the goal \verb|consumer([1|T], 0, R)| matches the head, the argument
\verb|[1|T]| (a list with writer tail) unifies with \verb|[X|Xs]|. The writer
\verb|Xs| in the head is assigned \verb|T?| (the tail's reader view).

The writer \verb|Xs| has now served its purpose: it received a value during
head unification. The SRSW syntactic restriction allows exactly one writer
occurrence per clause. Since \verb|Xs| already occurred as writer in the head,
it cannot appear as writer again in the body. Its paired reader \verb|Xs?|
must be used instead.

Similarly, \verb|Sum1| is a fresh writer created by the arithmetic assignment.
It occurs once as writer (receiving the sum). To pass the value to the
continuation, we use \verb|Sum1?|---passing the reader.

\mypara{Common Error}
Writing \verb|consumer(Xs, Sum1, Result)| would violate SRSW: \verb|Xs| would
occur twice as writer (in head and body), and \verb|Sum1| likewise. Beyond the
syntactic violation, this is semantically wrong: it attempts to receive through
channels that have already received their values.

\textbf{Principle:} In continuation calls, pass readers for values already
received. The writer served its purpose during unification; the reader carries
the value forward.
\end{formal}

The \verb|ground(X?)| guard ensures we only consume elements that are fully available.

\subsection{Concurrent Execution}

When producer and consumer run concurrently, they interleave:

\begin{verbatim}
GLP> producer(H, 5), consumer(H?, 0, R).
producer(X1, 5) :- :=/2(X3, -(5, 1)), producer(X4, X3?)
consumer([5 | X4?], 0, X2) :- :=/2(X5, +(0, 5)), consumer(X4?, X5?, X6)
:=/2(X3, -(5, 1)) :- true
producer(X4, 4) :- :=/2(X7, -(4, 1)), producer(X8, X7?)
:=/2(X5, +(0, 5)) :- true
consumer([4 | X8?], 5, X6) :- :=/2(X9, +(5, 4)), consumer(X8?, X9?, X10)
...
producer(X20, 0) :- true
consumer([], 15, X22) :- true
R = 15
→ succeeds
\end{verbatim}

The trace shows interleaving: the producer emits an element, the consumer processes it, the producer emits another, and so on. Neither runs to completion before the other starts---they cooperate through the shared stream.

\section{List Reversal}
\label{sec:streams-reverse}

Reversing a list illustrates the difference between naive recursion and efficient iteration with an accumulator.

\subsection{Naive Reverse}

The naive approach: reverse the tail, then append the head at the end.

\begin{verbatim}
reverse([], []).
reverse([X|Xs], Ys?) :-
    reverse(Xs?, Zs),
    append(Zs?, [X?], Ys).

append([], Ys, Ys?).
append([X|Xs], Ys, [X?|Zs?]) :- append(Xs?, Ys?, Zs).
\end{verbatim}

The base case \verb|reverse([], [])| illustrates empty list unification: \verb|[]| against \verb|[]| succeeds with the empty assignment (Appendix~\ref{appendix:list-unification}). The recursive clause shows cons cell matching: goal \verb|[a,b,c]| (which is \verb|[a|[b,c]]|) against head \verb|[X|Xs]| succeeds by unifying the head element and tail separately.

This is correct but inefficient. Each recursive call to \verb|reverse| triggers an \verb|append| that walks the entire accumulated result. For a list of length $n$, the total work is $1 + 2 + \cdots + n = O(n^2)$.

\subsection{Reverse with Accumulator}

The efficient version uses an accumulator to build the result during a single pass:

\begin{verbatim}
reverse(Xs, Ys?) :- reverse_acc(Xs?, [], Ys).

reverse_acc([], Acc, Acc?).
reverse_acc([X|Xs], Acc, Ys?) :- reverse_acc(Xs?, [X?|Acc?], Ys).
\end{verbatim}

Each element is prepended to the accumulator as we traverse the list. When we reach the end, the accumulator holds the reversed list. Total work: $O(n)$.

\subsection{Iteration vs. Recursion}

The accumulator version is \emph{iterative}: a single process steps through the list, updating its state (the accumulator) at each step. The call to \verb|reverse_acc| in the body is in \emph{tail position}---nothing remains to be done after it returns. The GLP runtime can execute this as a loop.

The naive version spawns a new process for each recursive call, building a chain of suspended \verb|append| goals waiting for their inputs. This is true recursion, but wasteful when a single-pass solution exists.

In general, when processing a list element-by-element with a single output, prefer the accumulator pattern. Reserve true recursion for divide-and-conquer algorithms like sorting, where parallelism provides benefit.

\section{Stream Merging}
\label{sec:streams-merge}

Merging combines multiple input streams into a single output stream. This is essential for many-to-one communication: multiple producers sharing a single consumer.

\subsection{Simple Fair Merge}

The simplest merge alternates between two input streams:

\begin{verbatim}
merge([X|Xs], Ys, [X?|Zs?]) :- merge(Ys?, Xs?, Zs).
merge(Xs, [Y|Ys], [Y?|Zs?]) :- merge(Xs?, Ys?, Zs).
merge([], Ys, Ys?).
merge(Xs, [], Xs?).
\end{verbatim}

The key to fairness is swapping the input streams after each element: \verb|merge(Ys?, Xs?, Zs)| puts the second input first. This ensures neither stream is starved.

\subsection{Dynamic Merge}
\label{sec:streams-dynamic-merge}

In many applications, the set of producers changes dynamically. A process may fork, creating a new stream that should join the merge. The \emph{dynamic merge} allows adding new streams via special \verb|merge(NewStream)| messages:

\begin{verbatim}
dmerge([merge(Ws)|Xs], Ys, Zs?) :-
    dmerger(Ws?, Xs?, Xs1), dmerge(Xs1?, Ys?, Zs).
dmerge(Xs, [merge(Ws)|Ys], Zs?) :-
    dmerger(Ws?, Ys?, Ys1), dmerge(Xs?, Ys1?, Zs).
dmerge([X|Xs], Ys, [X?|Zs?]) :-
    otherwise | dmerge(Ys?, Xs?, Zs).
dmerge(Xs, [Y|Ys], [Y?|Zs?]) :-
    otherwise | dmerge(Xs?, Ys?, Zs).
dmerge([], [], []).

dmerger(Ws, Xs, Out?) :- dmerge(Ws?, Xs?, Out).
\end{verbatim}

The \verb|otherwise| guard (Appendix~\ref{appendix:guard-unification}) succeeds only when all prior clauses have either failed or suspended. Here it ensures that regular messages are forwarded only when the head element is not a \verb|merge| request. Without \verb|otherwise|, a regular message \verb|[X|Xs]| would match the third clause even when the first clause (checking for \verb|merge(Ws)|) should apply. The \verb|otherwise| guard defers commitment until the runtime confirms no higher-priority clause can succeed.

\subsection{Static Balanced Merge Tree}

When the number of streams is known in advance, a balanced tree can be constructed explicitly:

\begin{verbatim}
merge_tree([Xs], Xs?).
merge_tree([X,Y|Rest], Out?) :-
    merge_layer([X?,Y?|Rest?], Layer),
    merge_tree(Layer?, Out).

merge_layer([], []).
merge_layer([Xs], [Xs?]).
merge_layer([Xs,Ys|Rest], [Zs?|Layer?]) :-
    merge(Xs?, Ys?, Zs),
    merge_layer(Rest?, Layer).
\end{verbatim}

For $n$ input streams, the resulting tree has height $\lceil \log_2 n \rceil$ and guarantees $O(n)$ bounded-waiting with $O(\log n)$ delay.

\section{Stream Distribution}

Distribution is the dual of merging: one input stream to many output streams. Two fundamental patterns serve most needs.

\subsection{Broadcast Distribution}

Broadcast sends each input element to all output streams:

\begin{verbatim}
distribute([X|Xs], [X?|Ys?], [X?|Zs?]) :- ground(X?) | distribute(Xs?, Ys, Zs).
distribute([], [], []).
\end{verbatim}

The \verb|ground(X?)| guard is essential. Without it, placing \verb|X| in multiple output positions would create multiple writer occurrences, violating SRSW. The guard verifies that \verb|X| contains no unbound variables, making replication safe---a ground term cannot expose writers to multiple readers. With the guard satisfied, multiple reader occurrences \verb|X?| are permitted.

\subsection{Indexed Distribution}

Indexed distribution routes each message to a specific output based on a tag:

\begin{verbatim}
distribute_indexed([send(1,X)|In], [X?|Out1?], Out2) :-
    distribute_indexed(In?, Out1, Out2).
distribute_indexed([send(2,X)|In], Out1, [X?|Out2?]) :-
    distribute_indexed(In?, Out1, Out2).
distribute_indexed([], [], []).
\end{verbatim}

Each input message is wrapped as \verb|send(N,X)| where \verb|N| indicates the destination. Pattern matching on \verb|N| selects the appropriate output stream.

\section{Stream Observers}
\label{sec:streams-observers}

An \emph{observer} monitors a stream without disrupting the communication between producer and consumer. This is useful for logging, debugging, or creating audit trails.

\subsection{Forwarding Observer}

The simplest observer sits between producer and consumer, forwarding elements while creating a copy:

\begin{verbatim}
observer([X|Xs], [X?|Ys?], [X?|Zs?]) :- ground(X?) | observer(Xs?, Ys, Zs).
observer([], [], []).
\end{verbatim}

The \verb|ground(X?)| guard is required because \verb|X?| appears twice---once forwarded to the consumer, once copied to the observation stream.

\subsection{Clause Selection via Writer-to-Writer Failure}
\label{sec:streams-wxw-selection}

Consider observing a stream being \emph{cooperatively} constructed, where you don't know in advance which party is writing at any moment:

\begin{verbatim}
observe([X|Xs], Ys?, [X?|Zs?]) :- ground(X?) |
    Ys = [X?|Ys1?], observe(Xs?, Ys1, Zs).
observe([X|Xs?], Ys, [X?|Zs?]) :- ground(X?) |
    Ys = [X?|Ys1], observe(Ys1?, Xs, Zs).
observe([], [], []).
\end{verbatim}

The two clauses handle opposite directions:
\begin{itemize}
\item Clause 1: First argument has writer tail \verb|Xs|, second has reader tail \verb|Ys?|. The first stream is producing.
\item Clause 2: First argument has reader tail \verb|Xs?|, second has writer tail \verb|Ys|. The second stream is producing.
\end{itemize}

This technique relies on writer-to-writer unification being \emph{immediate failure}, not suspension. If WxW suspended on an empty set, clause 2 would never be tried. The observer pattern demonstrates that WxW failure is semantically meaningful for clause selection, not merely an optimization.

The Writer/Reader Tail Discrimination table in Appendix~\ref{appendix:list-unification} summarizes these cases.

\section{Difference Lists}

A \emph{difference list} represents the difference between two potentially-indefinite streams. While streams may be unbounded, their difference is always finite---hence it represents a list.

\subsection{Representation}

A difference list has two components:
\begin{itemize}
\item The \emph{head}: a list structure with an unbound variable at its end (a ``hole'')
\item The \emph{tail}: the writer variable that can fill the hole
\end{itemize}

For example, the list \verb|[1,2]| as a difference list:
\begin{verbatim}
Head: [1,2|T?]    (structure with hole T?)
Tail: T           (writer that can fill the hole)
\end{verbatim}

\subsection{Constant-Time Append}

The power of difference lists: O(1) concatenation. To append two difference lists, unify the first tail with the second head:

\begin{verbatim}
append_dl(H1, T1?, T1, T2?, H1?, T2).
\end{verbatim}

The append completed in constant time---six unifications regardless of list length.

%% ============================================
%% Section 2: Buffered Communication
%% ============================================

\section{Buffered Communication}
\label{sec:buffered-communication}

\subsection{The Back-Pressure Problem}
\label{sec:backpressure-problem}

In producer-consumer systems, a fast producer can overwhelm a slow consumer. Without flow control, messages accumulate unboundedly, exhausting memory. \emph{Back-pressure} is the mechanism by which consumers signal producers to slow down.

In \GLP, the standard stream communication pattern offers no back-pressure---the producer can emit messages as fast as it runs, regardless of consumer speed. The solution is \emph{bounded buffers}.

\subsection{Difference-List Bounded Buffer}
\label{sec:buffer-difference-list}

We represent the buffer as a difference list \verb|Head--Tail|, where \verb|Head| is the read end and \verb|Tail| is the write end:

\begin{verbatim}
%% Send suspends when buffer is full
send(Msg, [Msg|NBuf?], NBuf).

%% Receive creates a new slot, allowing more sends
receive(Msg, [Msg|NBuf]--[_|NTail?], NBuf--NTail).

%% Close the buffer
close([end_of_stream|_]).
closed(end_of_stream).
\end{verbatim}

The \verb|--| operator is simply a binary functor with no special meaning---we use it to pair the read and write ends of the buffer. When the goal \verb|receive(I, Buf?, NBuf)| unifies with the head \verb|receive(Msg, [Msg|NBuf]--[_|NTail?], NBuf--NTail)|, the second argument demonstrates compound term unification (Appendix~\ref{appendix:compound-unification}): the goal's \verb|Buf?| must match the structure \verb|[...]--[...]|. If \verb|Buf?| is unbound (its paired writer not yet assigned), unification suspends. When \verb|Buf| receives a difference-list value, the goal reactivates and unification proceeds by matching the \verb|--| functor and recursively unifying its arguments.

The key insight: \verb|receive| not only extracts a message but also extends the tail with a new slot \verb|[_|NTail?]|. This ``credits'' the producer to send one more message.

\subsection{Opening a Buffer}

The \verb|open/2| predicate creates a buffer with a specified number of slots:

\begin{verbatim}
open(0, X--X).
open(N, [_|Y]--Z) :- N > 0 | N1 := N? - 1, open(N1?, Y--Z).
\end{verbatim}

For \verb|open(3, Buf)|, we get a buffer with 3 empty slots: \verb|[_,_,_|T]--T|. The producer can \verb|send| up to 3 messages before suspending.

\subsection{Flow Control Semantics}
\label{sec:buffer-flow-control}

The bounded buffer achieves flow control through suspension:

\begin{enumerate}
\item \textbf{Buffer not full:} \verb|send| succeeds immediately, filling a slot
\item \textbf{Buffer full:} \verb|send| attempts to unify with a full buffer and suspends
\item \textbf{Consumer receives:} \verb|receive| extends the tail, unblocking the suspended \verb|send|
\end{enumerate}

This creates a feedback loop: the consumer's consumption rate controls the producer's production rate.

\subsection{Network Switches}
\label{sec:network-switch}

A network switch routes messages between multiple ports based on destination:

\begin{verbatim}
switch2x2(In1, In2, Out1, Out2) :-
    receive(M, In1?, Ins1), send(M?, Out1?, Outs1) |
    switch2x2(Ins1?, In2?, Outs1?, Out2?).
switch2x2(In1, In2, Out1, Out2) :-
    receive(M, In2?, Ins2), send(M?, Out1?, Outs1) |
    switch2x2(In1?, Ins2?, Outs1?, Out2?).
switch2x2(In1, In2, Out1, Out2) :-
    receive(M, In1?, Ins1), send(M?, Out2?, Outs2) |
    switch2x2(Ins1?, In2?, Out1?, Outs2?).
switch2x2(In1, In2, Out1, Out2) :-
    receive(M, In2?, Ins2), send(M?, Out2?, Outs2) |
    switch2x2(In1?, Ins2?, Out1?, Outs2?).
\end{verbatim}

The guards \verb|receive(...), send(...)| ensure the clause commits only when both a message is available on an input and space is available on an output. If both outputs are full, all clauses suspend---back-pressure propagates from outputs to inputs.

%% ============================================
%% Section 3: Objects and Monitors
%% ============================================

\section{Objects and Monitors}
\label{sec:objects-monitors}

This section shows how reader/writer pairs naturally give rise to bidirectional channels and stateful servers. The concepts presented here---processes maintaining state in recursive parameters, responding to messages via streams, and communicating through incomplete message variables---are the \GLP realization of \emph{objects}. A \emph{monitor} is simply an object accessed by multiple clients through a merge network.

\subsection{Counter}
\label{sec:monitors-counter}

The simplest monitor maintains a counter responding to \verb|clear|, \verb|add|, and \verb|read(X)|:

\begin{verbatim}
counter(In) :- counter_loop(In?, 0).

counter_loop([clear|In], _) :- counter_loop(In?, 0).
counter_loop([add|In], C) :- C1 := C? + 1, counter_loop(In?, C1?).
counter_loop([read(V)|In], C) :- ground(C?) | V = C?, counter_loop(In?, C?).
counter_loop([], _).
\end{verbatim}

The \verb|read(V)| request is an \emph{incomplete message}: the client sends \verb|read(V)| retaining reader \verb|V?|, and the monitor binds writer \verb|V| to the current count. The \verb|ground(C?)| guard permits replication of \verb|C?| to both the response and the recursive call.

\begin{formal}{Which Guards Enable Multiple Reader Occurrences?}
\label{formal:guards-multiple-reads}

The counter's \verb|read| clause uses \verb|ground(C?)| to enable replication:
\begin{verbatim}
counter_loop([read(V)|In], C) :- ground(C?) | V = C?, counter_loop(In?, C?).
\end{verbatim}

Here \verb|C?| appears twice in the body. Without the guard, this would violate
SRSW. Why does \verb|ground(C?)| make it safe?

\mypara{The Danger of Replicating Readers}
If \verb|C?|'s value contains an unbound writer \verb|W|, then both occurrences
of \verb|C?| would have access to \verb|W|. Two references to the same writer
violates single-writer---both could attempt to bind \verb|W|.

\mypara{Ground Guard}
The guard \verb|ground(C?)| succeeds only if \verb|C?| contains no unbound
variables. A ground term can be safely replicated because there are no writers
to share.

\mypara{Type Guards}
Type guards like \verb|atom(X?)|, \verb|number(X?)|, and \verb|integer(X?)|
also enable multiple reader occurrences. An atom or number cannot contain
variables, so success implies groundness.

\mypara{The known Guard Does Not Enable Multiple Reads}
The guard \verb|known(X?)| only tests that \verb|X?| is bound to \emph{some}
value---which may contain unbound variables. After \verb|known(X?)| succeeds,
replicating \verb|X?| could still replicate access to writers embedded in the
value. Thus \verb|known| does not grant multiple-read permission.

\textbf{Summary:}
\begin{center}
\begin{tabular}{ll}
\textbf{Guard} & \textbf{Multiple reads?} \\
\hline
\verb|ground(X?)| & Yes (no variables) \\
\verb|atom(X?)|, \verb|number(X?)| & Yes (atoms/numbers have no variables) \\
\verb|compound(X?)| & Yes (compound structure exists) \\
\verb|known(X?)| & No (value may contain writers) \\
\end{tabular}
\end{center}
\end{formal}

From a unification perspective, when the monitor's clause head \verb|counter_loop([read(V)|In], C)| matches a goal, the \verb|V| in the message is a fresh writer (renamed from the clause). The body assignment \verb|V = C?| binds this writer to the current count. The induced reader assignment then propagates this value through the communication channel: the client's reader \verb|V?| receives the count.

\subsection{Shared Queue}
\label{sec:monitors-queue}

A more sophisticated monitor implements a shared queue using a difference-list:

\begin{verbatim}
queue(In) :- queue_loop(In?, Q, Q).

queue_loop([dequeue(X)|In], H, T) :-
    H = [X|H1?],
    queue_loop(In?, H1, T?).
queue_loop([enqueue(X)|In], H, T) :-
    T = [X|T1?],
    queue_loop(In?, H?, T1).
queue_loop([], _, _).
\end{verbatim}

The key insight: when the queue is empty and \verb|dequeue(X)| arrives, \verb|X| unifies with the head variable. When \verb|enqueue(V)| later arrives, \verb|V| fills the tail---which is the same variable. Thus \verb|X| receives \verb|V| through implicit synchronization.

\subsection{Objects and Encapsulation}

The counter demonstrates how object-oriented concepts emerge from process-based programming:

\begin{center}
\begin{tabular}{ll}
\textbf{OOP Concept} & \textbf{GLP Realization} \\
\hline
Private fields & Recursive parameters \\
Public methods & Message patterns \\
Method call & Stream element \\
Return value & Incomplete message variable \\
Object instance & Process with its own stream \\
\end{tabular}
\end{center}

\emph{Encapsulation} arises naturally: the state parameter is internal to the recursion---no external process can directly read or modify it. Messages are processed in stream order, so each message sees the state left by previous messages.

\subsection{Multiple Object Instances}
\label{sec:object-instances}

Each monitor call creates a distinct instance with its own state. Managing multiple named instances requires a registry:

\begin{verbatim}
registry([create(Name)|In], Objects) :-
    counter(Cmds?),
    registry(In?, [(Name?, Cmds)|Objects?]).
registry([(Name, Msg)|In], Objects) :-
    route(Objects?, Name?, Msg?, Objects1),
    registry(In?, Objects1?).
registry([], _).

route([(Name, [Msg|Rest?])|Objs], Name, Msg, [(Name?, Rest)|Objs?]).
route([Obj|Objs], Name, Msg, [Obj?|Objs1?]) :-
    otherwise |
    route(Objs?, Name?, Msg?, Objs1).
\end{verbatim}

\subsection{Comparison with the Actor Model}
\label{sec:actor-comparison}

\GLP objects resemble actors but with key differences:

\begin{center}
\begin{tabular}{lll}
\textbf{Feature} & \textbf{Actors} & \textbf{GLP Objects} \\
\hline
Message delivery & Asynchronous, unordered & Stream-ordered \\
Response mechanism & Explicit reply-to & Incomplete messages \\
State update & Internal mutation & Recursive parameter \\
Creation & \verb|spawn| primitive & Goal reduction \\
Identity & Actor reference & Stream endpoint \\
\end{tabular}
\end{center}

Stream-ordered delivery simplifies reasoning about state consistency---messages are processed in a deterministic sequence.

\subsection{Observing Monitors}
\label{sec:observing-monitors}

Observing a monitor's request stream requires handling \emph{incomplete messages}. Input operations like \verb|add(N)| have ground arguments, but output operations like \verb|value(V)| contain variables that the monitor will bind. A type-aware observer must handle both modes:

\begin{verbatim}
observe_accum([add(N)|In], [add(N?)|Out?], [add(N?)|Log?]) :-
    ground(N?) | observe_accum(In?, Out, Log).
observe_accum([value(V1?)|In], [value(V)|Out?], [value(V2?)|Log?]) :-
    duplicate(V?, V1, V2),
    observe_accum(In?, Out, Log).
observe_accum([], [], []).

duplicate(X, X?, X?) :- ground(X?) | true.
\end{verbatim}

\begin{formal}{Guard Placement: Avoiding Self-Deadlock}
\label{formal:guard-deadlock}

Consider an attempt to write a request-response protocol:
\begin{verbatim}
% INCORRECT - causes deadlock
alice([msg(hello, Reply)|Rest]) :-
    atom(Reply?) |       % Waits for Reply to be bound
    process(Reply?),     % Process the response
    alice(Rest?).
\end{verbatim}

This deadlocks. The guard \verb|atom(Reply?)| waits for \verb|Reply| to be
bound---but \verb|Reply| is a writer in alice's clause head. Only another
process (bob) can bind it, by receiving the message and filling in the response.
But alice hasn't sent the message yet; she's blocked in her guard.

\mypara{The Problem}
Alice tests a condition on her own output before producing that output.
This is backwards: she should send first, then wait.

\mypara{The Solution: Separate Send from Wait}
\begin{verbatim}
% CORRECT - send then wait
alice([msg(hello, Reply)|Rest]) :-
    alice_wait(Reply?, Rest?).

alice_wait(Reply, Rest) :-
    atom(Reply?) |       % Now waiting for bob's response
    process(Reply?),
    alice(Rest?).
\end{verbatim}

The first clause sends immediately (no guard). The continuation
\verb|alice_wait| receives the reply channel as a reader and waits for bob
to fill it.

\textbf{Principle:} Never guard on your own unbound writers. If you need to
wait for a response, send first (in a guardless clause), then wait in a
continuation that receives the channel as a reader.
\end{formal}

%% ============================================
%% Exercises
%% ============================================

\section{Exercises}
\label{sec:streams-exercises}

\subsection{Stream Fundamentals}

\begin{enumerate}
\item[$\star$] Implement \verb|length(Xs?, N)| that computes the length of a list using an accumulator.

\item[$\star$] Implement \verb|map_inc(Xs?, Ys)| that increments each element of a list of numbers.

\item[$\star\star$] Implement \verb|filter_even(Xs?, Ys)| that keeps only even numbers from a list.

\item[$\star\star$] Explain why list processing with accumulators is \emph{iterative} rather than \emph{recursive}.

\item Write a transducer \verb|filter(Pred, In, Out)| that outputs only elements satisfying predicate \verb|Pred|.

\item Write \verb|take(N, In, Out)| that outputs the first $N$ elements of a stream.

\item Write \verb|zip(Xs, Ys, Zs)| that pairs corresponding elements.

\item Implement a round-robin scheduler: given a list of streams, output one element from each in turn.

\item \label{ex:biased-merge} \textbf{(Biased Merge)} Implement a biased merge operator that maintains fairness in dynamically-constructed trees.
\end{enumerate}

\subsection{Buffered Communication}

\begin{enumerate}
\item \textbf{Bounded Buffer Size.} Experiment with different buffer sizes. What happens with size 0? Size 1?

\item \textbf{Priority Switch.} Modify the 2×2 switch to give priority to Input 1 over Input 2 when both have messages.

\item \textbf{Load Balancer.} Implement a load balancer that distributes messages from one input to multiple outputs, round-robin.
\end{enumerate}

\subsection{Objects and Monitors}

\begin{enumerate}
\item Extend the counter to support \verb|subtract| in addition to \verb|add|.

\item Implement a bounded buffer monitor that blocks producers when full and consumers when empty.

\item Implement a priority queue monitor with two input streams.

\item \textbf{Bank Account.} Implement a bank account object with messages \verb|deposit(Amount)|, \verb|withdraw(Amount, Success)|, and \verb|balance(B)|.

\item \textbf{Stack Object.} Implement a stack with \verb|push(X)|, \verb|pop(X)|, and \verb|is_empty(B)|.

\item \textbf{Observable Counter.} Implement a counter that notifies registered observers whenever its value changes.
\end{enumerate}

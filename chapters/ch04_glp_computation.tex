% chapters/ch04_glp_computation.tex - GLP Computation

\chapter{GLP Computation}
\label{ch:glp-computation}

This chapter presents the operational semantics of \GLP: how computations proceed, how communication happens asynchronously, and what safety properties are guaranteed.

\section{Asynchronous Resolvents}

In standard LP, a configuration is simply a goal (resolvent). In \GLP, we must also track pending messages---assignments from writers to their paired readers that haven't yet been delivered.

An \emph{asynchronous resolvent} is a pair $(G, \sigma)$ where:
\begin{itemize}
\item $G$ is a goal (conjunction of atoms)
\item $\sigma$ is a reader substitution---pending assignments to readers
\end{itemize}

The substitution $\sigma$ represents messages ``in flight.'' When a writer is assigned, the message goes into $\sigma$. Later, it is delivered to the reader.

\begin{example}[Asynchronous Resolvent]
Consider configuration:
\[
(G, \{X? := \text{hello}, Y? := 42\})
\]
This means goal $G$ is being computed, and there are two pending messages: $X?$ will receive ``hello'' and $Y?$ will receive 42.
\end{example}

\section{Transitions: Reduce and Communicate}

\GLP has two kinds of transitions:

\mypara{Reduce} Select an atom from the goal, find the first applicable clause, and reduce:
\begin{itemize}
\item The atom is replaced by the clause body
\item The writer substitution is applied to the goal
\item The reader counterpart is added to pending messages
\end{itemize}

\mypara{Communicate} Deliver a pending message:
\begin{itemize}
\item Select an assignment $X? := T$ from $\sigma$
\item Apply it to the goal: $G' = G\{X? := T\}$
\item Remove the assignment from pending: $\sigma' = \sigma \setminus \{X? := T\}$
\end{itemize}

These transitions can interleave arbitrarily, providing asynchronous communication.

\begin{formal}{GLP Transition System}
\begin{fdef}[GLP Goal/Clause Reduction]
Given GLP goal $A$ and clause $C$, with $H$ \texttt{:-} $B$ being $C$ renamed apart from $A$:
\begin{itemize}
\item \emph{succeeds with $(B, \sigma)$} if writer unification of $A$ and $H$ succeeds with $\sigma$
\item \emph{suspends on $W$} if writer unification suspends
\item \emph{fails} if writer unification fails
\end{itemize}
\end{fdef}

\begin{fdef}[GLP Transition System]
\label{def:glp-ts}
For program $M$ and initial goal $G_0$ (satisfying SRSW), the GLP transition system $(\calC, c0, \calT)$ where:
\begin{itemize}
\item $\calC$ is the set of asynchronous resolvents over $M$
\item $c0 = (G_0, \emptyset)$
\item $\calT$ contains all transitions $(G, \sigma) \to (G', \sigma')$ of two kinds:
\end{itemize}

\textbf{Reduce:} For atom $A \in G$ and first clause $C \in M$ where reduction succeeds with $(B, \hat\sigma)$:
\[
G' = (G \setminus \{A\} \cup B)\hat\sigma, \quad \sigma' = \sigma \circ \hat\sigma?
\]

\textbf{Communicate:} For assignment $\{X? := T\} \in \sigma$:
\[
G' = G\{X? := T\}, \quad \sigma' = \sigma \setminus \{X? := T\}
\]
\end{fdef}
\end{formal}

\section{Fairness}

The \emph{GLP fairness requirement}: A goal that can be reduced is eventually reduced.

Unlike LP where variable instantiation might cause a goal to become unreducible, \GLP's monotonicity (proven below) ensures that once a goal can be reduced, it remains reducible. This makes the fairness requirement meaningful and achievable.

\section{Computation Example}

Let's trace a computation with the merge program:

\begin{verbatim}
merge([X|Xs],Ys,[X?|Zs?]) :- merge(Ys?,Xs?,Zs).
merge(Xs,[Y|Ys],[Y?|Zs?]) :- merge(Xs?,Ys?,Zs).
merge([],[],[]).
\end{verbatim}

Initial goal: \verb|merge([1,2], [a,b], Out)|

\begin{enumerate}
\item $(G_0, \emptyset)$ where $G_0 = $ \verb|merge([1,2], [a,b], Out)|

\item \textbf{Reduce} with clause 1:
\begin{itemize}
\item Unify: $\{X := 1, Xs := [2], Ys := [a,b], Zs := Z_1, Out := [X_1?|Z_1?]\}$
\item New goal: \verb|merge([a,b]?, [2]?, Z_1)|
\item Pending: $\{X_1? := 1\}$
\end{itemize}

\item \textbf{Communicate} $X_1? := 1$:
\begin{itemize}
\item The 1 is now in $Out$: $Out = [1|Z_1?]$
\end{itemize}

\item \textbf{Reduce} with clause 1 (on the swapped arguments):
\begin{itemize}
\item Pattern matches $[a,b]$, extracts $a$
\item New goal: \verb|merge([2]?, [b]?, Z_2)|
\item Pending: $\{Z_1? := [a|Z_2?]\}$
\end{itemize}

\item Continue alternating...
\end{enumerate}

The output stream $Out$ is incrementally constructed as $[1, a, 2, b]$.

\section{GLP Safety Properties}

We now present the key safety properties that distinguish \GLP from standard LP.

\subsection{Computations are Deductions}

Despite the extensions, \GLP retains the fundamental logic programming property:

\begin{formal}{GLP Computations are Deductions}
\begin{fdef}[Pure Logic Variant]
Given GLP term or goal $T$, the \emph{pure logic variant} $L(T)$ replaces every reader $X?$ with its paired writer $X$.

For computation $r$, $L(r)$ replaces each $(G, \sigma)$ with $L(G)$, removing duplications from Communicate transitions.
\end{fdef}

\begin{fprop}[GLP Computations are Deductions]
\label{prop:glp-deduction}
For any finite GLP run $r$, let $L(r) = G_0 \xrightarrow{\sigma_1} G_1 \cdots G_n$ with $\sigma = \sigma_1 \cdots \sigma_n$.

Then $(G_0 \text{ :- } G_n)\sigma$ is a logical consequence of $L(M)$.
\end{fprop}

This means \GLP computations are sound: computed answers are logically entailed.
\end{formal}

\subsection{SRSW Preservation}

The SRSW invariant is maintained throughout computation:

\begin{formal}{SRSW Invariant}
\begin{fprop}[SRSW Invariant]
\label{prop:srsw-preservation}
If the initial goal $G_0$ satisfies SRSW, then every goal in the run satisfies SRSW.
\end{fprop}

\begin{proof}[Proof sketch]
By induction on computation length. The key observation is that SRSW clauses, when reduced against an SRSW goal, produce an SRSW result because:
\begin{enumerate}
\item Fresh variables from the clause satisfy SRSW by assumption
\item Writer unification only binds writers, not creating duplicates
\item The reader counterpart creates exactly one pending assignment per binding
\end{enumerate}
\end{proof}
\end{formal}

\subsection{Acyclicity}

The occurs check in readers prevents circular terms:

\begin{formal}{Acyclicity}
\begin{fprop}[Acyclicity]
\label{prop:acyclicity}
If the initial goal $G_0$ contains no circular terms, then no goal in the run contains a circular term.
\end{fprop}

The restriction that $X?$ cannot occur in $X\sigma$ (in the writer substitution definition) prevents the formation of cycles like $X = f(X?)$.
\end{formal}

\subsection{Monotonicity}

The most distinctive safety property of \GLP:

\begin{formal}{Monotonicity}
\begin{flem}[Reader-Instance]
\label{lem:reader-only}
In any GLP run $G_0 \to G_1 \to \cdots$, if transition $G_i \to G_{i+1}$ does not reduce atom $A \in G_i$, then $A\tau \in G_{i+1}$ where $\tau$ instantiates only readers.
\end{flem}

\begin{fprop}[Monotonicity]
\label{prop:glp-monotonicity}
In any GLP run, if atom $A \in G_i$ can reduce with clause $C$, then for any $j > i$:
\begin{enumerate}
\item Either $A$ has been reduced by step $j$
\item Or there exists $A' \in G_j$ where $A' = A\tau$ for some reader substitution $\tau$, and $A'$ can reduce with $C$
\end{enumerate}
\end{fprop}

This is crucial: in LP, variable instantiation can cause a previously reducible goal to fail. In \GLP, once reducible, always reducible (until actually reduced).
\end{formal}

\section{Why Monotonicity Matters}

Monotonicity has profound implications:

\mypara{No Deadlock from Lost Opportunities} A goal waiting for data doesn't prevent other goals from proceeding, and when the data arrives, the goal is still reducible.

\mypara{Simple Fairness} The fairness requirement is achievable: just ensure every reducible goal eventually gets a turn.

\mypara{Robust Scheduling} The scheduler has freedom---any order works, as long as it's fair.

\mypara{Distributed Execution} In a distributed setting, delays don't cause failures. A message arriving late doesn't invalidate pending computations.

\section{Deterministic Implementation}

The nondeterministic transition system is a specification. For implementation, we need deterministic choices:

\begin{itemize}
\item \textbf{Goal selection}: Which atom to reduce next?
\item \textbf{Message delivery}: When to apply pending assignments?
\end{itemize}

Appendix~\ref{app:irglp} presents an ``implementation-ready'' deterministic specification. The key ideas:
\begin{itemize}
\item Goals are scheduled round-robin
\item Suspended goals are reactivated when their awaited readers receive values
\item Messages are delivered when the receiving goal becomes active
\end{itemize}

\section{From Single-Agent to Multiagent}

So far we've considered a single computation---one agent. The next major extension is to multiple agents, each with their own computation, communicating through shared reader/writer pairs.

This is the subject of Chapter~\ref{ch:multiagent}, where we define multiagent \GLP and prove it grassroots.

\section{Summary}

\GLP computation features:
\begin{itemize}
\item \textbf{Asynchronous resolvents}: Goals plus pending messages
\item \textbf{Two transitions}: Reduce (compute) and Communicate (deliver)
\item \textbf{Fairness}: Reducible goals are eventually reduced
\item \textbf{Safety}: Computations are deductions, SRSW preserved, no cycles, monotonic
\end{itemize}

The monotonicity property is key: it enables robust distributed execution without complex failure handling.

\section{Exercises}

\begin{enumerate}
\item[$\star$] Trace the full computation of \verb|merge([1], [a], Out)| showing all configurations.

\item[$\star$] What happens if we query \verb|merge(X, Y, [1,2,3])| with $X$ and $Y$ uninstantiated?

\item[$\star\star$] Explain why monotonicity fails in standard LP. Give a concrete example.

\item[$\star\star$] Design a goal that never terminates but is fair (every subgoal gets reduced infinitely often).

\item[$\star\star\star$] Prove that if all goals in a \GLP computation eventually become reducible, the computation is deadlock-free.
\end{enumerate}
